{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "90Vp4XA67T"
      },
      "source": [
        "# Max Todd\n",
        "# Applied Machine Learning\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from time import time"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "8wYOMPCEGf"
      },
      "source": [
        "# Load the processed dataset (get from running preprocessing.py)\n",
        "traindf = pd.read_csv('./data/preprocessed/train.csv',\n",
        "                      encoding='unicode_escape')\n",
        "testDF = pd.read_csv('./data/preprocessed/test.csv',\n",
        "                     encoding='unicode_escape')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ZmqSIREtN8"
      },
      "source": [
        "# remove nan\n",
        "traindf.dropna(inplace=True)\n",
        "testDF.dropna(inplace=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "BlKHXm7fUo"
      },
      "source": [
        "# Create storage for results\n",
        "models = [\n",
        "            'NB with NTD',\n",
        "            'NB with TTD',\n",
        "            'SVM with NTD',\n",
        "            'SVM with TTD'\n",
        "         ]\n",
        "\n",
        "accuracies = [0 for i in range(len(models))]\n",
        "trainTime = [0 for i in range(len(models))]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "iSEF0piTip"
      },
      "source": [
        "Naive Bayes with normalized text data\n",
        "Accuracy = 0.6293984108967083"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "J2LVgTkcTk"
      },
      "source": [
        "# Start timing\n",
        "train = time()\n",
        "\n",
        "# Make and train Naive Bayes model using the normalized text without stop words\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model.fit(traindf['normalizeNoStop'], traindf['sentiment'])\n",
        "\n",
        "# Stop timing\n",
        "train = time() - train\n",
        "\n",
        "# Add time to results\n",
        "trainTime[0] = train"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "8Fjyc2TC6S"
      },
      "source": [
        "# Predict\n",
        "predicted = model.predict(testDF['normalizeNoStop'])\n",
        "\n",
        "# Get the accuracy using the normalized text without stop words\n",
        "accuray = accuracy_score(predicted, testDF['sentiment'])\n",
        "print(f'NB with normalized accuracy={accuray}')\n",
        "print(f'time: {train * 1000} ms')\n",
        "\n",
        "# Add accuracy to results\n",
        "accuracies[0] = accuray"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "NB with normalized accuracy=0.6293984108967083\ntime: 285.4340076446533 ms\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "r0I3f1kaN1"
      },
      "source": [
        "Naive Bayes with tokenized text data\n",
        "Accuracy = 0.6285471055618616"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "a5OQ7lKu9p"
      },
      "source": [
        "# Start timing\n",
        "train = time()\n",
        "\n",
        "# Make and train Naive Bayes model using the tokenized text\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model.fit(traindf['tokenized'], traindf['sentiment'])\n",
        "\n",
        "# Stop timing\n",
        "train = time() - train\n",
        "\n",
        "# Add time to results\n",
        "trainTime[1] = train"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "DXq8qypW7x"
      },
      "source": [
        "# Predict\n",
        "predicted = model.predict(testDF['tokenized'])\n",
        "\n",
        "# Get the accuracy using the tokenized text\n",
        "accuray = accuracy_score(predicted, testDF['sentiment'])\n",
        "print(f'NB with tokenized accuracy={accuray}')\n",
        "print(f'time: {train * 1000} ms')\n",
        "\n",
        "# Add accuracy to results\n",
        "accuracies[1] = accuray"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "NB with tokenized accuracy=0.6285471055618616\ntime: 291.6879653930664 ms\n"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "fT2ShfNN6w"
      },
      "source": [
        "SVM with normalized text data\n",
        "Accuracy = 0.7017593643586834"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "g0WkFzfmMp"
      },
      "source": [
        "# Start timing\n",
        "train = time()\n",
        "\n",
        "# Make and train Naive Bayes model using the normalized text without stop words\n",
        "model = make_pipeline(TfidfVectorizer(), SVC())\n",
        "model.fit(traindf['normalizeNoStop'], traindf['sentiment'])\n",
        "\n",
        "# Stop timing\n",
        "train = time() - train\n",
        "\n",
        "# Add time to results\n",
        "trainTime[2] = train"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "vnI5Nygdwv"
      },
      "source": [
        "# Predict\n",
        "predicted = model.predict(testDF['normalizeNoStop'])\n",
        "\n",
        "# Get the accuracy using the tokenized text\n",
        "accuray = accuracy_score(predicted, testDF['sentiment'])\n",
        "print(f'SVM with normalized text data accuracy = {accuray}')\n",
        "print(f'time: {train * 1000} ms')\n",
        "\n",
        "# Add accuracy to results\n",
        "accuracies[2] = accuray"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SVM with normalized text data accuracy = 0.7017593643586834\ntime: 130257.7600479126 ms\n"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "j31xd1bEUi"
      },
      "source": [
        "SVM with tokenized text data\n",
        "Accuracy = 0.7023269012485811"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "2Zd1Pegj2t"
      },
      "source": [
        "# Start timing\n",
        "train = time()\n",
        "\n",
        "# Make and train Naive Bayes model using the normalized text without stop words\n",
        "model = make_pipeline(TfidfVectorizer(), SVC())\n",
        "model.fit(traindf['tokenized'], traindf['sentiment'])\n",
        "\n",
        "# Stop timing\n",
        "train = time() - train\n",
        "\n",
        "# Add time to results\n",
        "trainTime[3] = train"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "RgursE1VMN"
      },
      "source": [
        "# Predict\n",
        "predicted = model.predict(testDF['tokenized'])\n",
        "\n",
        "# Get the accuracy using the tokenized text\n",
        "accuray = accuracy_score(predicted, testDF['sentiment'])\n",
        "print(f'SVM with tokenized text data = {accuray}')\n",
        "print(f'time: {train * 1000} ms')\n",
        "\n",
        "# Add accuracy to results\n",
        "accuracies[3] = accuray"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SVM with tokenized text data = 0.7023269012485811\ntime: 135365.88191986084 ms\n"
        }
      ],
      "execution_count": 4
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}